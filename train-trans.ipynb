{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e8dbe87",
   "metadata": {
    "cellId": "dsjmeuiu5ooqr5um2elwq",
    "execution_id": "63041a91-be5f-4ca8-9fcc-ca840d96b49c"
   },
   "source": [
    "## Обучение генеративной трансформерной модели с помощью `transformers`\n",
    "\n",
    "В этой работе мы познакомимся на практике с процессом тренировки большой трансформерной языковой модели. Поскольку такая тренировка требует существенных вычислительных ресурсов, выполнять эту работу рекомендуется в Yandex DataSphere, в которой доступны вычислитльные узлы с одни или двумя графическими процессорами Tesla V100.\n",
    "\n",
    "### Архитектура трансформеров\n",
    "\n",
    "В рамках этой работы мы предполагаем, что вы уже знакомы с архитектурой трансформеров, например, по [статье из ML-хэндбука](https://academy.yandex.ru/handbook/ml/article/transformery). Также для первоначального знакомства рекомендую заметку [Jay Alammar. The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/), и её частичный [русскоязычный перевод](https://habr.com/ru/articles/486358/).\n",
    "\n",
    "Мы не будем в рамках работы создавать архитетуру нейросети \"с нуля\". Если вам инетересно изучить реализацию трансформеров - рекомендую посмотреть на [NanoGPT](https://github.com/karpathy/nanoGPT). Подробно эта реализация разбирается в [этом видео](https://www.youtube.com/watch?v=kCc8FmEb1nY).\n",
    "\n",
    "### Библиотека `transformers` и её друзья\n",
    "\n",
    "Стандартом де факто в реализации трансформеров служит библиотека `transformers` от [HuggingFace](http://huggingface.co). Она содержит в себе реализацию большого количества используемых трансформерных архитектур, а также ряд полезных инструментов для их обучения. Многие инструменты также оформлены в виде отдельных библиотек, которые хорошо работают вместе:\n",
    "\n",
    "* `tokenizers` - быстрая реализация различных токенизаторов, позволяющих разделять входной текст на токены\n",
    "* `datasets` - манипулирование большими датасетами\n",
    "* `evaluate` - вычисление различных метрик и оценка результатов обучения\n",
    "* `accelerate` - реализация вычислений на множестве GPU и на вычислительных кластерах\n",
    "\n",
    "Для начала, установим необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5909a2",
   "metadata": {
    "cellId": "rbd025oj0my1im4ob4369",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:06:06.004559Z",
     "iopub.status.busy": "2023-11-22T13:06:06.003903Z",
     "iopub.status.idle": "2023-11-22T13:06:17.327182Z",
     "shell.execute_reply": "2023-11-22T13:06:17.325725Z",
     "shell.execute_reply.started": "2023-11-22T13:06:06.004524Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install transformers tokenizers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c343afb",
   "metadata": {
    "cellId": "ksyl1g4026iecxq8gx3y7i",
    "execution_id": "1ca722bd-54d0-49cb-ba0f-f31785d40372"
   },
   "source": [
    "В текущем варианте при работе в DataSphere возникают проблемы при использовании файлового хранилища. Для решения проблем нам нужно установить последнюю версию библиотеки `s3fs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a581a6a",
   "metadata": {
    "cellId": "ung9q52gkel6fodtt5ncyx",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:06:22.446953Z",
     "iopub.status.busy": "2023-11-22T13:06:22.446097Z",
     "iopub.status.idle": "2023-11-22T13:06:34.003628Z",
     "shell.execute_reply": "2023-11-22T13:06:34.002501Z",
     "shell.execute_reply.started": "2023-11-22T13:06:22.446896Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install fsspec==2024.10.0\n",
    "# %pip list\n",
    "\n",
    "# %pip install --upgrade datasets\n",
    "\n",
    "# %pip install --upgrade git+https://github.com/dask/s3fs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f15e8",
   "metadata": {
    "cellId": "26xvyymzgf9rbljkfquk3",
    "execution_id": "ed5b5cd9-8b09-47c2-aefc-76c2e1b11867"
   },
   "source": [
    "### Подготовка датасета\n",
    "\n",
    "В нашем примере, мы будем обучать виртуального Льва Толстого. Для этого, возьмём все основные романы писателя, и подготовим их них датасет. В качестве отправной точки будет использовать тексты из [библиотеки Мошкова](http://lib.ru). Соберем ссылки на романы Анна Каренина, Война и Мир и др. в один список:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d7ffcc",
   "metadata": {
    "cellId": "iclg75lmp4eq0s1e06tgz8",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:06:34.006420Z",
     "iopub.status.busy": "2023-11-22T13:06:34.005468Z",
     "iopub.status.idle": "2023-11-22T13:06:34.023538Z",
     "shell.execute_reply": "2023-11-22T13:06:34.022313Z",
     "shell.execute_reply.started": "2023-11-22T13:06:34.006372Z"
    }
   },
   "outputs": [],
   "source": [
    "# urls = [\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0039.shtml\",\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0040.shtml\",\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0050.shtml\",\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0060.shtml\",\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0070.shtml\",\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0080.shtml\",\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0090.shtml\",\n",
    "#     \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_1860_dekabristy.shtml\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305027b2",
   "metadata": {
    "cellId": "tckha1m6ce8l6uzswytdo",
    "execution_id": "79951af7-53d9-4ec2-aa1c-c6fb34818c24"
   },
   "source": [
    "Теперь скачаем все материалы и подготовим из них один большой текстовый файл. Для того нам понадобится убрать HTML-теги, а также несколько первоначальных строчек в каждом из файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ed7313",
   "metadata": {
    "cellId": "nnln4ab6z2rmu8k09ydl",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:06:37.190694Z",
     "iopub.status.busy": "2023-11-22T13:06:37.189627Z",
     "iopub.status.idle": "2023-11-22T13:06:38.738412Z",
     "shell.execute_reply": "2023-11-22T13:06:38.737280Z",
     "shell.execute_reply.started": "2023-11-22T13:06:37.190658Z"
    }
   },
   "outputs": [],
   "source": [
    "# import html\n",
    "# import re\n",
    "# \n",
    "# import requests\n",
    "# \n",
    "# \n",
    "# def download(url):\n",
    "    # return requests.get(url).text\n",
    "# \n",
    "# \n",
    "# code borrowed from here: https://github.com/pallets/markupsafe/blob/0.23/markupsafe/__init__.py#L21\n",
    "# striptags_re = re.compile(r\"(<!--.*?-->|<[^>]*>)\")\n",
    "# entity_re = re.compile(r\"&([^;]+);\")\n",
    "# \n",
    "# \n",
    "# def to_text(s):\n",
    "    # return html.unescape(striptags_re.sub(\"\", s))\n",
    "# \n",
    "# \n",
    "# def beautify(s):\n",
    "    # lines = [x.strip() for x in s.split(\"\\n\") if x.strip() != \"\"]\n",
    "    # for i in range(min(100, len(lines))):\n",
    "        # if lines[i] == \"-->\":\n",
    "            # break\n",
    "    # return \"\\n\".join(lines[i + 1 :] if i < 100 else lines)\n",
    "# \n",
    "# \n",
    "# with open(\"dataset.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # for u in urls:\n",
    "        # text = beautify(to_text(download(u)))\n",
    "        # f.write(text + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b835e2",
   "metadata": {
    "cellId": "nunyvossq6o0yteon40rkk",
    "execution_id": "1b9df5be-83bf-4505-ae10-7fcd613f2ecf"
   },
   "source": [
    "### Токенизация\n",
    "\n",
    "Нейросети работают с числами, поэтому первым этапом является токенизация текста, т.е. разбиение его на атомарные элементы, которые затем можно добавить в словарь, и представлять текст как последовательность индексов в словаре. Текст можно токенизировать по буквам, или по словам.\n",
    "\n",
    "При построении современных генеративных сетей текст обычно разбивают на фрагменты таким образом, чтобы частота появления каждого фрагмента в тексте была примерно одинакова. Это лежит в основе т.н. Byte-Pair Encoding (BPE). Подробнее можно прочитать [в этой статье](https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt).\n",
    "\n",
    "Для обучения своего токенизатора используем библиотеку `tokenizers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d25b461",
   "metadata": {
    "cellId": "x7fii1yudivznf9h1jgxb",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:06:44.265151Z",
     "iopub.status.busy": "2023-11-22T13:06:44.264232Z",
     "iopub.status.idle": "2023-11-22T13:06:47.935533Z",
     "shell.execute_reply": "2023-11-22T13:06:47.934344Z",
     "shell.execute_reply.started": "2023-11-22T13:06:44.265075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/files/private_data/hand/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tokenizers as tok\n",
    "import transformers as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e470b754",
   "metadata": {
    "cellId": "jjhwu4gsmle8v2ojdyjukv",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:06:53.487505Z",
     "iopub.status.busy": "2023-11-22T13:06:53.486439Z",
     "iopub.status.idle": "2023-11-22T13:06:56.051785Z",
     "shell.execute_reply": "2023-11-22T13:06:56.050627Z",
     "shell.execute_reply.started": "2023-11-22T13:06:53.487469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tok.Tokenizer(tok.models.BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = tok.pre_tokenizers.Whitespace()\n",
    "trainer = tok.trainers.BpeTrainer(special_tokens=[\"[PAD]\"])\n",
    "tokenizer.train([\"dataset.txt\"], trainer)\n",
    "tokenizer.enable_padding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147ea7e",
   "metadata": {
    "cellId": "elx7gkaggq7m8oqmajnxh",
    "execution_id": "f07d8caa-a3c4-40d8-b637-f1234bc4f642"
   },
   "source": [
    "А данном случае мы используем два специальных токена - `[UNK]` для представления неизвестного токена (такое случится, если на вход попадёт символ, который токенизатор не видел при обучении), и `[PAD]` для **паддинга** - он используется, если нужно дополнить последовательность до определённой длины.\n",
    "\n",
    "Вот как можно закодировать входной текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04579048",
   "metadata": {
    "cellId": "d1cjx8u0oy8rixk9y6m8q",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:07:08.891474Z",
     "iopub.status.busy": "2023-11-22T13:07:08.890755Z",
     "iopub.status.idle": "2023-11-22T13:07:08.922664Z",
     "shell.execute_reply": "2023-11-22T13:07:08.921593Z",
     "shell.execute_reply.started": "2023-11-22T13:07:08.891438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Иван',\n",
       " 'С',\n",
       " 'иг',\n",
       " 'изму',\n",
       " 'н',\n",
       " 'до',\n",
       " 'вич',\n",
       " 'подошел',\n",
       " 'к',\n",
       " 'окну',\n",
       " 'и',\n",
       " 'закашлялся',\n",
       " '.',\n",
       " 'Вечер',\n",
       " 'ело',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Иван Сигизмундович подошел к окну и закашлялся. Вечерело.\").tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f66e2",
   "metadata": {
    "cellId": "kxbtrltl0yra2oywv2mxe"
   },
   "source": [
    "Видим, что популярные слова токенизируются целиком, а те, которые встречаются в тексте редко или не встречаются вовсе - разбиваются на фрагменты.\n",
    "\n",
    "### Генеративные трансформеры\n",
    "\n",
    "Для генерации текста используются архитектуры GPT - Generative Pre-trained Transformers. В то время как полноценные трансформеры являются энкодер-декодерной архитектурой, т.е. могут решать задачи преобразования одного вида последовательности в другую, GPT является только декодером, т.к. способно прогнозировать распределение вероятности следующего слова по начальной части последовательности.\n",
    "\n",
    "Мы используем архитектуру GPT-2, которая, с одной стороны, не слишком огромна, а с другой - может неплохо обучиться. Сперва попробуем натренировать такую архитетуру \"с нуля\".\n",
    "\n",
    "Дла начала нам потребуется преобразовать наш токенизатор к объекту `ttokenizer`, который понимает библиотека transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8928e282",
   "metadata": {
    "cellId": "76f33tr549x3izkn7g8t7w",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:07:20.166309Z",
     "iopub.status.busy": "2023-11-22T13:07:20.165368Z",
     "iopub.status.idle": "2023-11-22T13:07:20.306703Z",
     "shell.execute_reply": "2023-11-22T13:07:20.305635Z",
     "shell.execute_reply.started": "2023-11-22T13:07:20.166270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "ttokenizer = tr.PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91488224-b24c-44d6-a805-b4cea7ad833a",
   "metadata": {},
   "source": [
    "Теперь создадим непосредственно нейросетевую модель GPT2. При этом основные параметры (количество слоёв, количество голов внимания и т.д. оставим по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b18d8be",
   "metadata": {
    "cellId": "7yflw4cbp4mapc77dbn4o",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:07:21.219041Z",
     "iopub.status.busy": "2023-11-22T13:07:21.218320Z",
     "iopub.status.idle": "2023-11-22T13:07:37.475252Z",
     "shell.execute_reply": "2023-11-22T13:07:37.474143Z",
     "shell.execute_reply.started": "2023-11-22T13:07:21.219005Z"
    }
   },
   "outputs": [],
   "source": [
    "config = tr.GPT2Config(\n",
    "    vocab_size=len(vocab),\n",
    "    bos_token_id=tokenizer.token_to_id(\"[CLS]\"),\n",
    "    eos_token_id=tokenizer.token_to_id(\"[EOS]\"),\n",
    ")\n",
    "gpt = tr.GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379893b-f03d-48cc-b09f-7c085b15f0ce",
   "metadata": {},
   "source": [
    "Веса вновь созданной модели инициализируются случайным образом, поэтому если мы попросим такую модель сгенерировать текст - получится бессмыслица:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eec498e",
   "metadata": {
    "cellId": "pd21krza2dmw3ecnel8ara",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:07:37.478365Z",
     "iopub.status.busy": "2023-11-22T13:07:37.477330Z",
     "iopub.status.idle": "2023-11-22T13:07:39.412338Z",
     "shell.execute_reply": "2023-11-22T13:07:39.411260Z",
     "shell.execute_reply.started": "2023-11-22T13:07:37.478319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мне нравится бессмысленно бессмысленно обез we ощупал объясня мягкими девушкам Трои Трои Трои Трои Трои лампа сен сен сен сен Коло сен сен мягкими неудержимо доклады людь лампа лампа лампа объясня объясня пониже пониже неудержимо обратила дядюшки дядюшки неудержимо неудержимо заса обратила обратила Трои celle обратила обратила ульта сен сен клима клима'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = gpt.generate(\n",
    "    **ttokenizer(\"Мне нравится \", return_tensors=\"pt\"),\n",
    "    max_new_tokens=50,\n",
    "    top_k=3,\n",
    "    do_sample=True\n",
    ")\n",
    "ttokenizer.decode(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4bd5a4-3378-4a38-ac3d-07f48ad00047",
   "metadata": {},
   "source": [
    "Теперь нам надо научиться подавать на вход модели фрагменты текста для обучения. Для этого существует библиотека `datasets`, входящее в семейство трансформерных библиотек HuggingFace. Помимо того, что эта библиотека умеет работать с разными форматами входных датасетов, она также интегрирована с HuggingFace Hub, и может в одну строчку загружать множество имеющихся на этом сайте датасетов.\n",
    "\n",
    "В нашем случае мы загрузим датасет из текстового файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f83e7a",
   "metadata": {
    "cellId": "ymos6h01o5efyusa8fmapr",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:07:51.422222Z",
     "iopub.status.busy": "2023-11-22T13:07:51.421328Z",
     "iopub.status.idle": "2023-11-22T13:07:53.369455Z",
     "shell.execute_reply": "2023-11-22T13:07:53.368323Z",
     "shell.execute_reply.started": "2023-11-22T13:07:51.422187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Он взял своею большою рукой меня за руку, и пожал так крепко, честно, только что не больно. Я думала, что он поцелует мою руку, и нагнулась было к нему, но он еще раз пожал мне руку и прямо в глаза посмотрел своим твердым и веселым взглядом.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"text\", data_files=\"dataset.txt\")\n",
    "dataset[\"train\"][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c042844-9998-4a05-bc69-165b77896fcf",
   "metadata": {},
   "source": [
    "Далее нам необходимо научиться токенизировать датасет, т.е. преобразовывать в числовые тензоры, которые затем мы будем подавать на вход нейросети в процессе обучения. Для этого опишем фукнцию `tokenize`, которая будет возвращать словарь с несколькими полями:\n",
    "\n",
    "* `input_ids` - это собственно номера слов входной последовательности в словаре\n",
    "* `token_type_ids` - содержит нули. Это поле используется в более сложных сценариях, например, когда мы тренируем сеть отвечать на вопросы по тексту. В этом случае нам нужно подать на вход текст + вопрос, и это поле позволяет различать между несколькими разными по смыслу фрагментами входной последовательности\n",
    "* `atttention_mask` показывает, какая часть входной последовательности значима. Для организации последовательности в minibatch нам может потребоваться дополнить последовательность до максимальной длины, и поле `attention_mask` содержит 1 в тех позициях, которые соответствуют исходной последовательности\n",
    "\n",
    "Такой формат входных данных типичен для трансформерной архитектуры. Также мы передаем последовательность значений целевой переменной `labels`, но поскольку наша задача - это генерация текста, то в качестве `labels` мы передаём копию исходного текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f7b2ad",
   "metadata": {
    "cellId": "svhzelwehjpwlu9emfsib",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:07:59.902663Z",
     "iopub.status.busy": "2023-11-22T13:07:59.901666Z",
     "iopub.status.idle": "2023-11-22T13:08:03.142172Z",
     "shell.execute_reply": "2023-11-22T13:08:03.140784Z",
     "shell.execute_reply.started": "2023-11-22T13:07:59.902606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2302, 1780, 561, 2201],\n",
       " 'token_type_ids': [0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1],\n",
       " 'labels': [2302, 1780, 561, 2201]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    x = ttokenizer(x[\"text\"])\n",
    "    x[\"labels\"] = x[\"input_ids\"].copy()\n",
    "    return x\n",
    "\n",
    "\n",
    "ds = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "ds[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5800b193-896c-4b68-97cf-584cd69e1880",
   "metadata": {},
   "source": [
    "Для обучения лучше всего использовать длинные фрагменты текста, поэтому мы сгруппируем все последовательности токенов в блоки размером `block_size`. Для этого мы сначала сконкатенируем все последовательности, а потом разобъем их на блоки. В данном случае мы не будем даже разбивать последовательность на слова и/или предложения - как показывает практика, такой упрощенный подход также даёт хорошие результаты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b55b96",
   "metadata": {
    "cellId": "omlv6mxp3tqt8ebm0awq",
    "execution": {
     "iopub.execute_input": "2023-11-22T14:34:15.997454Z",
     "iopub.status.busy": "2023-11-22T14:34:15.996759Z",
     "iopub.status.idle": "2023-11-22T14:34:18.603876Z",
     "shell.execute_reply": "2023-11-22T14:34:18.602744Z",
     "shell.execute_reply.started": "2023-11-22T14:34:15.997410Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "block_size = 1024\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "dsb = ds.map(group_texts, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd56ffd1-995d-44e0-89d6-7740a0f075b6",
   "metadata": {},
   "source": [
    "Теперь мы готовы к обучению! Для задания параметров обучения мы создаём объект `TrainingArguments`, в котором задаем директорию, куда будут записываться промежуточные результаты обучения, число эпох, скорость обучения и т.д. Затем на основе этих параметров создаём объект `Trainer`.\n",
    "\n",
    "Обратите внимание, что размер записываемой на диск сети GPT-2 может быть весьма большим (около 1.4 Gb), что может привести к исчерпанию размера вашей домашней директории в DataSphere. Исходя из этого лучше выбирать параметры `save_steps` и `num_train_epochs` таким образом, чтобы количество записываемых на диск чекпоинтов не превышало 3-5 шт.\n",
    "\n",
    "Для начала стоит попробовать пообучать сеть в течение 30-90 минут, чтобы увидеть, что она начинает складывать слова более менее правдоподобно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408488f",
   "metadata": {
    "cellId": "4re85sxlr1hkjznsu65qq",
    "execution": {
     "iopub.execute_input": "2023-11-22T13:08:29.022680Z",
     "iopub.status.busy": "2023-11-22T13:08:29.021433Z",
     "iopub.status.idle": "2023-11-22T13:08:56.689692Z",
     "shell.execute_reply": "2023-11-22T13:08:56.688516Z",
     "shell.execute_reply.started": "2023-11-22T13:08:29.022635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется pynvml module not found, please install pynvml\n",
      "10\n",
      "GPU 0: NVIDIA A100-PCIE-40GB\n",
      "GPU 1: NVIDIA A100-PCIE-40GB\n",
      "GPU 2: NVIDIA A100-PCIE-40GB\n",
      "GPU 3: NVIDIA A100-PCIE-40GB\n",
      "GPU 4: NVIDIA A100-PCIE-40GB\n",
      "GPU 5: NVIDIA A100-PCIE-40GB\n",
      "GPU 6: NVIDIA A100-PCIE-40GB\n",
      "GPU 7: NVIDIA A100-PCIE-40GB\n",
      "GPU 8: NVIDIA A100-PCIE-40GB\n",
      "GPU 9: NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 7:\n",
    "    device = torch.device(\"cuda:6\")\n",
    "    print(f\"Используется {torch.cuda}\")\n",
    "else:\n",
    "    raise Exception(\"GPU 7 не доступен\")\n",
    "\n",
    "gpt.to(device)\n",
    "\n",
    "# Проверка доступных GPU\n",
    "print(torch.cuda.device_count())  # Сколько GPU доступно\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")  # Список всех доступных GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b27f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111521/85631145.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = tr.Trainer(\n"
     ]
    }
   ],
   "source": [
    "targs = tr.TrainingArguments(\n",
    "    output_dir=\"gpt2-scratch\",\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=200,\n",
    "    save_steps=1500,\n",
    ")\n",
    "trainer = tr.Trainer(\n",
    "    gpt,\n",
    "    args=targs,\n",
    "    train_dataset=dsb[\"train\"],\n",
    "    tokenizer=ttokenizer,\n",
    "    data_collator=tr.default_data_collator,  # tr.DataCollatorForLanguageModeling(tokenizer=ttokenizer,mlm=False)\n",
    ")\n",
    "# trainer.args.per_device_train_batch_size = 4  # уменьшите размер батча\n",
    "# trainer.args.local_rank = -1  # для использования одного GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1112141c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 5 on device 5.\nOriginal Traceback (most recent call last):\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 96, in _worker\n    output = module(*input, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1304, in forward\n    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py\", line 1293, in forward\n    return F.cross_entropy(\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/functional.py\", line 3479, in cross_entropy\n    return torch._C._nn.cross_entropy_loss(\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 938.00 MiB. GPU 5 has a total capacity of 39.50 GiB of which 3.81 MiB is free. Including non-PyTorch memory, this process has 0 bytes memory in use. Of the allocated memory 10.34 GiB is allocated by PyTorch, and 27.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/transformers/trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2479\u001b[0m )\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/transformers/trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3585\u001b[0m ):\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/transformers/trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:193\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    192\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 193\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:212\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[1;32m    211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:126\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    124\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 126\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/_utils.py:715\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 5 on device 5.\nOriginal Traceback (most recent call last):\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 96, in _worker\n    output = module(*input, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1304, in forward\n    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py\", line 1293, in forward\n    return F.cross_entropy(\n  File \"/files/private_data/hand/.venv/lib/python3.10/site-packages/torch/nn/functional.py\", line 3479, in cross_entropy\n    return torch._C._nn.cross_entropy_loss(\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 938.00 MiB. GPU 5 has a total capacity of 39.50 GiB of which 3.81 MiB is free. Including non-PyTorch memory, this process has 0 bytes memory in use. Of the allocated memory 10.34 GiB is allocated by PyTorch, and 27.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcda58f-f57d-42b6-88bd-8316b31816be",
   "metadata": {},
   "source": [
    "Теперь посмотрим, как работает генерация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fba89",
   "metadata": {
    "cellId": "leffxl7khjsji465vkdloo",
    "execution": {
     "iopub.execute_input": "2023-11-22T14:14:51.133759Z",
     "iopub.status.busy": "2023-11-22T14:14:51.132840Z",
     "iopub.status.idle": "2023-11-22T14:14:53.740387Z",
     "shell.execute_reply": "2023-11-22T14:14:53.739172Z",
     "shell.execute_reply.started": "2023-11-22T14:14:51.133700Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Пьер закашлялся и что в Москве был был быть. Но она была у нее не хотелось сказать своей смерти, и он был не знал, с тем, как было видеть этого лица, которое она узнала, что она не желала, что он сам. Она подошла к ней ; я не была рада, как ни о будущем ее, о чем она не понимала этого чувства не могла понять, но не знать, что она хотела думать об этом не будет и она не могла, как и не говорила о нее, что бы сделать. Она, но ничего не могла понять, как не было не понимала, но все это легко будет у меня и о том, как можно так, а она видела она не могла сделать, как и даже как он не видела, как бы она почувствовала'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ttokenizer = tr.PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "res = gpt.generate(\n",
    "    **ttokenizer(\"Пьер закашлялся и\", return_tensors=\"pt\").to(\"cuda\"),\n",
    "    max_new_tokens=150,\n",
    "    do_sample=True\n",
    ")\n",
    "ttokenizer.decode(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d8ea2-4d80-4c55-b2ae-ba94873d3483",
   "metadata": {},
   "source": [
    "Кажется, что сгенерированный текст пока ещё не слишком осмысленный. Но сравните его с первоначальным текстом, сгенерированным необученной нейросетью - в нём почти не было корректных грамматических конструкций. За примерно час обучения сеть уже стала неплохо понимать, какие слова хорошо сочетаются друг с другом, и в целом начала говорить более осмысленно. Помните, что трансформерная модель - сложная, и для обучения полноценной GPT-2 \"с нуля\" требуются сотни и тысячи GPU-часов.\n",
    "\n",
    "> Прежде, чем переходить к следующим экспериментам, очистим память. Если вдруг на следующем этапе возникнет переполнение памяти GPU, может потребоваться перезапуск ядра ноутбука - выберите к меню Kernel -> Restart Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903b42d",
   "metadata": {
    "cellId": "c5wv13vypc4shk1wncy5cm",
    "execution": {
     "iopub.execute_input": "2023-11-22T14:16:34.824292Z",
     "iopub.status.busy": "2023-11-22T14:16:34.823428Z",
     "iopub.status.idle": "2023-11-22T14:16:35.140660Z",
     "shell.execute_reply": "2023-11-22T14:16:35.139479Z",
     "shell.execute_reply.started": "2023-11-22T14:16:34.824254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gpt = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70215e43-c58e-4182-bda1-726a0b5c8939",
   "metadata": {},
   "source": [
    "## До-обучение GPT-2\n",
    "\n",
    "За приемлемое время сложно достичь приемлемого качества обучения трансформера, поэтому обычно используют предобученные модели (поэтому в названии GPT и фигурирует слово *Pretrained*), которые уже научились \"читать\" на нужном языке, и их необходимо лишь немного \"доучить\" под требуемую предметную область или стиль. В этом случае процесс обучения модели почти не отличается от того, что мы делали ранее - с той лишь разницей, что необходимо использовать токенизатор, который использовался при обучении исходной модели.\n",
    "\n",
    "Для начала, загрузим предобученную модель **ruGPT** и соответствующий токенизатор, и посмотрим, как эта модель умеет продолжать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd8bbd-77e9-442a-a36a-3d1883568f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:38:05.664573Z",
     "iopub.status.busy": "2023-11-22T14:38:05.663434Z",
     "iopub.status.idle": "2023-11-22T14:38:29.085092Z",
     "shell.execute_reply": "2023-11-22T14:38:29.083780Z",
     "shell.execute_reply.started": "2023-11-22T14:38:05.664535Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804f6bce89204af090408c175fe13b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3386569b8204b9eb7f19fb2e9fa1bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d9c578fdd44553837c24568b8f774a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51797b9af4b340b5b6ab1844261f2004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Мне нравится, что вы \\nне знаете, кто вы и что вы.\\n\\n- Я знаю только, кто вы, - сказала она. - Вы -\\n\\nнесколько человек.\\n\\n- Вы -\\n\\nне совсем\\n\\nчеловек.\\n\\n- Я'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tr.AutoTokenizer.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
    "gpt = tr.GPT2LMHeadModel.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
    "res = gpt.generate(\n",
    "    **tokenizer(\"Мне нравится, что вы \", return_tensors=\"pt\"),\n",
    "    max_new_tokens=50,\n",
    "    top_k=3,\n",
    "    do_sample=True\n",
    ")\n",
    "tokenizer.decode(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616cda96-ac15-49fe-ad2c-d7762cf9bf8d",
   "metadata": {},
   "source": [
    "На самом деле качество модели *очень сильно* зависит от количества параметров, и тот факт, что мы взяли модель **ruGPTsmall** сказывается на качестве текста. Но зато и процесс обучения будет существенно быстрее!\n",
    "\n",
    "Поскольку мы теперь используем другой токенизатор, то нам нужно заново токенизировать датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6b616-0bb8-4ade-89c6-846643699ac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:39:23.217520Z",
     "iopub.status.busy": "2023-11-22T14:39:23.216267Z",
     "iopub.status.idle": "2023-11-22T14:39:26.558165Z",
     "shell.execute_reply": "2023-11-22T14:39:26.556877Z",
     "shell.execute_reply.started": "2023-11-22T14:39:23.217453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c50add30d84007b56bb75d5e3f7dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"text\", data_files=\"dataset.txt\")\n",
    "ds = dataset.map(lambda x: \n",
    "                 tokenizer(x[\"text\"]), batched=True, remove_columns=[\"text\"])\n",
    "dsb = ds.map(group_texts, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f324969-e2ed-4085-862d-906ab5bf9777",
   "metadata": {},
   "source": [
    "Сам по себе процесс запуска обучения и указания параметров ничем не отличается от обучения трансформерной модели \"с нуля\". Возможно, при до-обучении имеет смысл указывать чуть более низкий `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced1c5f-8a27-47c0-9dd4-276f5cd33f2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:39:31.920477Z",
     "iopub.status.busy": "2023-11-22T14:39:31.919469Z",
     "iopub.status.idle": "2023-11-22T16:02:29.020689Z",
     "shell.execute_reply": "2023-11-22T16:02:29.019128Z",
     "shell.execute_reply.started": "2023-11-22T14:39:31.920441Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:39:34.067839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5700' max='5700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5700/5700 1:22:50, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.277100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.957200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.872600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5700, training_loss=2.3302585534882128, metrics={'train_runtime': 4971.7497, 'train_samples_per_second': 9.154, 'train_steps_per_second': 1.146, 'total_flos': 2.378280075264e+16, 'train_loss': 2.3302585534882128, 'epoch': 30.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs = tr.TrainingArguments(\n",
    "    output_dir=\"gpt2-finetune\",\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=200,\n",
    "    save_steps=1500,\n",
    ")\n",
    "trainer = tr.Trainer(\n",
    "    gpt,\n",
    "    args=targs,\n",
    "    train_dataset=dsb[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=tr.default_data_collator,  # tr.DataCollatorForLanguageModeling(tokenizer=ttokenizer,mlm=False)\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9e6b4-eee1-4071-9aa1-a4b5a96a1c0a",
   "metadata": {},
   "source": [
    "Смотрим на результат генерации после обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b3d10-d230-4e55-a6ae-645630603dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T16:14:15.085816Z",
     "iopub.status.busy": "2023-11-22T16:14:15.084658Z",
     "iopub.status.idle": "2023-11-22T16:14:16.067040Z",
     "shell.execute_reply": "2023-11-22T16:14:16.065953Z",
     "shell.execute_reply.started": "2023-11-22T16:14:15.085770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Мне нравится, что вы  знаете  это, и я люблю это, -- сказал он, -- и  надеюсь  на  вас.  Вы  непротивоположная, я всегда был и буду  тем и другим,  я  всегдапротивоположный.-- '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = gpt.generate(\n",
    "    **tokenizer(\"Мне нравится, что вы \", return_tensors=\"pt\").to(\"cuda\"),\n",
    "    max_new_tokens=50,\n",
    "    top_k=3,\n",
    "    do_sample=True\n",
    ")\n",
    "tokenizer.decode(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bdac8e-d3db-459f-a864-6c693a642a2e",
   "metadata": {},
   "source": [
    "Кажется, что мы получили сильно более хороший результат!\n",
    "\n",
    "## Параллелизация обучения\n",
    "\n",
    "Надеюсь, вы убедились, что на DataSphere можно обучать достаточно мощные модели, однако время, затрачиваемое на обучение, всё ещё остаётся большим. Чтобы ускорить этот процесс, обычно используют параллельное обучение на нескольких GPU одновременно.\n",
    "\n",
    "Самым распространённым вариантом параллелизма является параллелизм по данным (Data Parallel Training), в котором на каждый из обучающих GPU подаётся свой поток данных (т.е. своя часть исходного датасета). При этом на каждом обучающем шаге каждый GPU вычисляет свой градиент ошибки, которые затем усредняются и используются для синхронного обновления моделей на всех обучающих процессорах.\n",
    "\n",
    "Различают два варианта обучения на нескольких GPU:\n",
    "* **Data Parallel** - обычно используется, когда несколько GPU установлены на одном компьютере. В этом случае используется почти такой же код обучения на Python, как для однопроцессорного варианта, модель оборачивается в класс `torch.nn.DataParallel`, и минибатч распределяется по нескольким доступным на данном компьютере GPU.\n",
    "* **Distributed Data Parallel** используется в более общем случае, когда есть кластер из компьютеров с GPU.\n",
    "\n",
    "Подробнее про параллельное обучения можно почитать [в руководстве PyTorch](https://pytorch.org/docs/stable/distributed.html#distributed-basics).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c51b4-ae57-4c1a-997e-5d71eb820256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:30:02.748101Z",
     "iopub.status.busy": "2023-11-22T14:30:02.747033Z",
     "iopub.status.idle": "2023-11-22T14:30:02.875407Z",
     "shell.execute_reply": "2023-11-22T14:30:02.874294Z",
     "shell.execute_reply.started": "2023-11-22T14:30:02.747981Z"
    },
    "tags": []
   },
   "source": [
    "## Заключение\n",
    "\n",
    "Одна из целей данной работы заключалась в том, чтобы продемонстрировать, что обучение сложных языковых моделей с помощью современных библиотек является сравнительно простой задачей - но требующей значительных вычислительных ресурсов. Как только мы выходим за рамки вычислений, которые можно сделать за несколько часов на общедоступных инструментах типа Google Colab - у нас возникает потребность в облачных вычислительных ресурсах.\n",
    "\n",
    "Yandex DataSphere обеспечивает легкий переход от локального Jupyter Notebook или публичного облака Google Colab / Kaggle к выделенной облачной инфраструктуре в Yandex Cloud. В DataSphere вы можете:\n",
    "\n",
    "* легко настроить подключения к облачным хранилищам данных, \n",
    "* взаимодействовать с другими участниками проекта\n",
    "* использовать GitHub для контроля версий кода\n",
    "* бережливо расходовать ресурсы благодаря режиму Serverless или возможности легкого переключения между виртуальными вычислителями\n",
    "\n",
    "Для эффективной работы в DataSphere в ней необходимо немного привыкнуть, но когда этап привыкания пройдёт - вы сможете эффективно пользоваться этим инструментом и получать удовольствие от работы в нём!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829425e-b2bb-496c-85f0-5cbe8805a798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "notebookId": "1481bb9f-dbbc-4e48-8133-aa84fa48d93b",
  "notebookPath": "sda-homeworks/train-trans/train-trans.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
